4. Store and retrieve data in pig.

Apache Pig is a high-level platform for processing large data sets using Hadoop. 
Hadoop stores raw data coming from various sources like IOT, 
websites, mobile phones, etc. and preprocessing is done in Map-reduce. 
Pig framework converts any pig job into Map-reduce hence we can use the pig to do the ETL 
  (Extract Transform and Load) process on the raw data. 

â€¢	Developed by Yahoo!
â€¢	Part of the Hadoop ecosystem.
â€¢	Uses a scripting language called Pig Latin.

Key Features
â€¢	High-level language (Pig Latin) for data analysis.
â€¢	Extensible: You can write your own functions (UDFs) in Java, Python, etc..
â€¢	Handles complex data like nested structures.
â€¢	Optimized: Pig scripts are automatically converted into optimized MapReduce jobs.

Pig Latin Overview
Pig Latin is a data flow language. It uses a step-by-step approach where each step in the script defines a transformation.
Apache pig framework has below major components as part of its Architecture:
1.	Pig Latin Script
2.	Grunt Shell (Interactive shell)
3.	Pig Engine (Executes the script)
4.	Parser(checks syntax, output in DAG)
5.	Optimizer(perform logical optimization)
6.	Compiler(generates a series of Map-Reduce jobs)
7.	Execution Modes: (submitted to Hadoop in sorted order)
  o	Local Mode: Runs on a single machine (good for testing)
  o	MapReduce Mode: Runs on Hadoop cluster
 
Use Cases
â€¢	ETL (Extract, Transform, Load) operations.
â€¢	Log processing.
â€¢	Data preparation for machine learning.
â€¢	Ad-hoc data analysis.

Advantages of Pig
â€¢	Easier to write and understand than raw MapReduce.
â€¢	Faster development time.
â€¢	Scales well with Hadoop.
â€¢	Good for schema-less, semi-structured data.

Limitations
â€¢	Not suitable for real-time processing.
â€¢	Less popular now due to rise of Apache Spark.
â€¢	Requires Hadoop infrastructure.

Apache Pig Installation (Local Mode)
Step 1: Prerequisites
Before installing Pig, make sure you have the following installed:
1.	Java (JDK) â€“ version 8 is recommended.
2.	Hadoop (optional for local mode, but useful).
3.	Pig binary package.

Step 2: ğŸ“¦ Download Apache Pig
Get the latest stable Pig release from the official site:
wget https://downloads.apache.org/pig/pig-0.17.0/pig-0.17.0.tar.gz

Step 3: ğŸ“‚ Extract and Set Up Pig
Extract the downloaded archive:
tar -xvzf pig-0.17.0.tar.gz
mv pig-0.17.0 pig

Add Pig to your environment variables:
export PIG_HOME=~/pig
export PATH=$PIG_HOME/bin:$PATH

Step 4:  Run Pig in Local Mode
You can now launch Pig in local mode (doesn't need Hadoop cluster):
pig -x local

Youâ€™ll enter the interactive Grunt shell:

grunt>

Try a simple command:

grunt> a = LOAD 'data.txt' USING PigStorage(',') AS (id:int, name:chararray);
grunt> DUMP a;
(Make sure data.txt is in the same directory or give full path)

Step 5: Verify Installation
To test, create a simple Pig Latin script (e.g., script.pig):
-- script.pig
data = LOAD 'data.txt' USING PigStorage(',') AS (id:int, name:chararray);
filtered = FILTER data BY id > 10;
DUMP filtered;

Run it:
pig -x local script.pig

!!!Basic Pig Commands

1. Fs: This will list all the files in the HDFS

grunt> fs â€“ls

2. Clear: This will clear the interactive Grunt shell.

grunt> clear

3. History:

This command shows the commands executed so far.
grunt> history

4. Reading Data: Assuming the data resides in HDFS, we need to read data to Pig.

grunt> college_students = LOAD â€˜hdfs://localhost:9000/pig_data/college_data.txtâ€™

USING PigStorage(â€˜,â€™)

as ( id: int, firstname:chararray, lastname:chararray, phone:chararray,

city:chararray );

PigStorage() is the function that loads and stores data as structured text files.

5. Storing Data: The store operator stores the processed/loaded data.

grunt> STORE college_students INTO â€˜ hdfs://localhost:9000/pig_Output/ â€˜ USING PigStorage (â€˜,â€™);

Here, â€œ/pig_Output/â€ is the directory where the relation needs to be stored.

6. Dump Operator: This command displays the results on the screen. It usually helps in debugging.

grunt> Dump college_students;

7. Describe Operator: It helps the programmer view the relationâ€™s schema.

grunt> describe college_students;

8. Explain: This command helps to review the logical, physical, and map-reduce execution plans.

grunt> explain college_students;

9. Illustrate operator: This gives step-by-step execution of statements in Pig Commands.

grunt> illustrate college_students;
